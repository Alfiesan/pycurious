{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 3 - Optimisation routine\n",
    "\n",
    "In Examples 2a and 2b we computed the Curie depth for a single point using a fixed window. Here, we use `CurieOptimise` object to compute the Curie depth over an entire magnetic anomaly.\n",
    "\n",
    "`CurieOptimise` inherits all methods from `CurieGrid` in addition to:\n",
    "\n",
    "- iteratively evaluate the Curie depth across the magnetic anomaly\n",
    "- add priors to limit spurious Curie depth determinations\n",
    "- optimise Curie depth parameters using constraints from an objective function\n",
    "\n",
    "### Contents\n",
    "\n",
    "- [The inverse problem](#The-inverse-problem)\n",
    "- [Sensitivity analysis](#Sensitivity analysis)\n",
    "- [Compare Bouligand to Tanaka](#Compare-Bouligand-to-Tanaka)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pycurious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load x,y,anomaly\n",
    "mag_data = np.loadtxt(\"../data/test_mag_data.txt\")\n",
    "\n",
    "nx, ny = 305, 305\n",
    "\n",
    "x = mag_data[:,0]\n",
    "y = mag_data[:,1]\n",
    "d = mag_data[:,2].reshape(ny,nx)\n",
    "\n",
    "xmin, xmax = x.min(), x.max()\n",
    "ymin, ymax = y.min(), y.max()\n",
    "\n",
    "# initialise CurieOptimise object\n",
    "grid = pycurious.CurieOptimise(d, xmin, xmax, ymin, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get centroids\n",
    "\n",
    "window_size = 200e3\n",
    "xc_list, yc_list = grid.create_centroid_list(window_size, spacingX=10e3, spacingY=10e3)\n",
    "\n",
    "print(\"number of centroids = {}\".format(len(xc_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The inverse problem\n",
    "\n",
    "It is notoriously difficult to estimate uncertainties from Curie depth determinations. Intuitively, the fewer points in the power spectrum should result in higher uncertainty, but it is difficult to quantify these uncertainties in practise. For [Bouligand *et al.*, 2009](http://doi.wiley.com/10.1029/2009JB006494) it is difficult to determine the values of $\\beta$ and $\\Delta z$ since both control the slope of the power spectrum at low wavenumbers. Similarly, for [Tanaka *et al.*, 1999](http://linkinghub.elsevier.com/retrieve/pii/S0040195199000724) the lower and upper ranges of the power spectrum used to compute $z_b$ and $z_t$ is highly subjective and can result in significantly different Curie depths.\n",
    "\n",
    "Here, we aim to assess the uncertainty of Curie depth determinations using a sensitivity analysis. The approach we outline here is not necessarily the most statistically robust methodology, but it is intended as a practical means to compute Curie depth whilst considering its uncertainty.\n",
    "\n",
    "First we find the best model with no priors to evaluate the heterogeneity in the signal we extract from the magnetic anomaly. We use the commonly used $\\ell_2$-norm objective function to calculate misfit. The objective function can be accessed (and modified) under `grid.objective_function`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no priors\n",
    "grid.reset_priors()\n",
    "\n",
    "beta, zt, dz, C = grid.optimise_routine(window_size, xc_list, yc_list)\n",
    "\n",
    "# plot results\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, sharex=True, sharey=True, figsize=(10,10))\n",
    "\n",
    "sc1 = ax1.scatter(xc_list, yc_list, c=beta)\n",
    "sc2 = ax2.scatter(xc_list, yc_list, c=zt)\n",
    "sc3 = ax3.scatter(xc_list, yc_list, c=dz)\n",
    "sc4 = ax4.scatter(xc_list, yc_list, c=C)\n",
    "\n",
    "fig.colorbar(sc1, ax=ax1, label=r\"$\\beta$\")\n",
    "fig.colorbar(sc2, ax=ax2, label=r\"$z_t$\")\n",
    "fig.colorbar(sc3, ax=ax3, label=r\"$\\Delta z$\")\n",
    "fig.colorbar(sc4, ax=ax4, label=r\"$C$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sensitivity analysis\n",
    "\n",
    "The sensitivity analysis requires defining a prior distribution to sample from. The default is a Gaussian normal distribution,\n",
    "\n",
    "$$\n",
    "P(\\mathbf{m}) = \\frac{1}{\\sqrt{2\\pi} \\sigma_p} \\exp \\left( \\frac{-\\mathbf{m}^2}{2 \\sigma_p^2} \\right)\n",
    "$$\n",
    "\n",
    "but other distributions can be defined from the `scipy.stats` module. We repeat the inversion multiple times, sampling different values from $P(\\mathbf{m})$ to evaluate the uncertainty in each variable. Note: $\\mathbf{m}$ is the variables $\\beta, z_t, \\Delta z, C$ for the Bouligand approach or $z_t, z_b $ for the Tanaka approach.\n",
    "\n",
    "Prior distributions are added by\n",
    "\n",
    "```python\n",
    "from scipy import stats\n",
    "beta_p = stats.norm(3.0, 1.0)\n",
    "grid.add_prior(beta=beta_p)\n",
    "```\n",
    "\n",
    "and can be accessed from a dictionary:\n",
    "\n",
    "```python\n",
    "prior = grid.prior_pdf['beta'] # stats.norm object\n",
    "prior = grid.prior['beta'] # stats.norm object arguments (3.0, 1.0)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "beta_p = stats.norm(3.0, 1.0)\n",
    "zt_p = stats.norm(0.0, 1.0)\n",
    "dz_p = stats.norm(12.0, 8.0)\n",
    "C_p = stats.norm(-17.0, 5.0)\n",
    "\n",
    "grid.add_prior(beta=beta_p, zt=zt_p, dz=dz_p, C=C_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of simulations to run for each centroid\n",
    "nsim = 10\n",
    "\n",
    "beta, zt, dz, C = grid.sensitivity_routine(nsim, window_size, xc_list, yc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,4))\n",
    "\n",
    "\n",
    "for i, (label, var) in enumerate([('beta', beta), ('zt', zt), ('dz', dz), ('C', C)]):\n",
    "    \n",
    "    # prior distribution\n",
    "    prior = grid.prior_pdf[label]\n",
    "    p, sigma_p = prior.mean(), prior.std()\n",
    "    \n",
    "    # posterior distribution\n",
    "    P, sigma_P = var[:,0].mean(), var[:,1].mean()\n",
    "    post = stats.norm(P, sigma_P)\n",
    "    \n",
    "    x_samples = np.linspace(p-2*sigma_p, p+2*sigma_p, 100)\n",
    "    \n",
    "    # plot pdf\n",
    "    ax = fig.add_subplot(1,4,i+1, xlabel=label)\n",
    "    ax.plot(x_samples, prior.pdf(x_samples), label=\"prior\")\n",
    "    ax.plot(x_samples, post.pdf(x_samples), label=\"posterior\")\n",
    "    ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The precision of the values are properly resolved "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
